# ğŸ§  Test Technique R&D â€” Suivi Automatique des Prix E-commerce

Ce projet est une **application Python complÃ¨te** permettant de **scraper automatiquement des produits e-commerce**, **suivre les changements de prix** et **mettre Ã  jour un Google Sheet** via lâ€™**API Google Sheets**, tout en exposant les donnÃ©es Ã  travers une **API REST (FastAPI)**.

---

## ğŸš€ FonctionnalitÃ©s principales

âœ… Scraping automatique de plusieurs catÃ©gories de produits
âœ… Export structurÃ© des donnÃ©es vers Google Sheets
âœ… API REST complÃ¨te (FastAPI)
âœ… Scheduler automatique  (Pas tester de mon cote )
âœ… Alertes e-mail sur changements de prix (Pas tester de mon cote )

---

## ğŸ§± Structure du projet

```
projet/
â”œâ”€â”€ main.py              # Application FastAPI (API REST)
â”œâ”€â”€ scraper.py           # Logique de scraping avec Selenium
â”œâ”€â”€ sheets_manager.py    # Gestion des interactions avec Google Sheets
â”œâ”€â”€ models.py            # ModÃ¨les Pydantic pour la validation des donnÃ©es
â”œâ”€â”€ config.py            # Configuration et variables dâ€™environnement
â”œâ”€â”€ credentials.json     # Identifiants du compte de service Google 
â”œâ”€â”€ requirements.txt     # DÃ©pendances Python
â”œâ”€â”€ .env                 # Variables dâ€™environnement
â””â”€â”€ README.md            # Documentation complÃ¨te
â””â”€â”€ tests.md            # Documentation complÃ¨te
â””â”€â”€â””â”€â”€ test.api.py            #  Le test des APIs
â””â”€â”€â””â”€â”€ scraper.py            # Tester la Logique de scraping avec Selenium
â””â”€â”€â””â”€â”€  sheets_manager.py    # tester la Gestion des interactions avec Google Sheets
```

---

## âš™ï¸ Installation et PrÃ©paration

### 1ï¸âƒ£ Cloner le dÃ©pÃ´t

```bash
git clone https://github.com/<ton-nom-utilisateur>/price-tracker.git
cd price-tracker
```

### 2ï¸âƒ£ CrÃ©er un environnement virtuel

```bash
python -m venv venv
venv\Scripts\activate      # Windows
```

### 3ï¸âƒ£ Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

---

## ğŸ”‘ Configuration de lâ€™API Google Sheets

### Ã‰tape 1 : Activer lâ€™API Google Sheets

1. Rendez-vous sur [Google Cloud Console](https://console.cloud.google.com/).
2. CrÃ©ez un **nouveau projet** : Test WeShore Automation.
3. Activez les APIs :

   * **Google Sheets API**
   * **Google Drive API**
4. CrÃ©ez un **compte de service** (IAM & Admin â†’ Comptes de service)." scrapy-data@test-weshore-automation.iam.gserviceaccount.com
5. TÃ©lÃ©chargez le fichier `credentials.json` et placez-le Ã  la working Folder du projet.

---

### Ã‰tape 2 : CrÃ©er et partager le Google Sheet

1. CrÃ©ez une nouvelle feuille Google Sheets nommÃ©e **`Product Price Tracker`**.
2. Partagez-la avec lâ€™adresse e-mail du **compte de service** (ex: `scrapy-data@test-weshore-automation.iam.gserviceaccount.com`).
3. Copiez lâ€™**1_7YOn6iLkYl87zfWGYIUHEI6evo15wl7FEDbd5NiD5k** (dans lâ€™URL) :

   ```
   https://docs.google.com/spreadsheets/d/1_7YOn6iLkYl87zfWGYIUHEI6evo15wl7FEDbd5NiD5k/edit
   ```

---

### Ã‰tape 3 : CrÃ©er le fichier `.env`

```bash
SPREADSHEET_ID=1_7YOn6iLkYl87zfWGYIUHEI6evo15wl7FEDbd5NiD5k
HEADLESS_MODE=True
...
```

---

## ğŸ§  Utilisation

### ğŸ•µï¸ 1. Tester le scraper seul

Pour tester uniquement le scraping sans lancer lâ€™API :

```bash
python scraper.py
```

---

### ğŸ§© 2. Lancer lâ€™API FastAPI

```bash
uvicorn main:app --reload --port 8000
```

Lâ€™API sera disponible Ã  :
ğŸ‘‰ [http://127.0.0.1:8000](http://127.0.0.1:8000)

ğŸ‘‰ Pour le Swagger :  [http://127.0.0.1:8000/docs#/default](http://127.0.0.1:8000/docs#/default)

---

## ğŸ”— Endpoints REST

### ğŸ“¤ POST `/scrape/now`

DÃ©clenche immÃ©diatement le scraping et met Ã  jour Google Sheets.

```bash
curl -X POST "http://127.0.0.1:8000/scrape/now" 

     Request Body '{"categories": ["Laptops", "Tablets", "Touch"], "update_sheets": true}'
```


---

### ğŸ“„ GET `/products/{category}`

RÃ©cupÃ¨re les produits dâ€™une catÃ©gorie spÃ©cifique.

```bash
curl http://127.0.0.1:8000/products/Laptops
Parameter : Laptops
```
```

---

### ğŸ“‰ GET `/price-changes`
- NB : J'ai mis la logic mais n'est pas encore tester , j'ai besoin de temps pour debugger .
Retourne les derniers changements de prix dÃ©tectÃ©s.

```bash
curl http://127.0.0.1:8000/price-changes
```


```

---

## ğŸ•° Automatisation quotidienne 

Pour exÃ©cuter le scraping automatiquement chaque jour Ã  **9h00**, J'active le **scheduler APScheduler** avec le script below:

```python
# main.py
from apscheduler.schedulers.background import BackgroundScheduler

def tache_scraping_quotidienne():
    print("Lancement du scraping quotidien...")
    <!-- Appel A la fonction main qui se base ici : @app.post("/scrape/now")  -->
    scrape_now()

scheduler = BackgroundScheduler()
scheduler.add_job(tache_scraping_quotidienne, 'cron', hour=9, minute=0)
scheduler.start()
```

---

## âœ‰ï¸ Alertes e-mail (optionnel)

Envoyez un e-mail lorsquâ€™un changement de prix est dÃ©tectÃ© :

```python
import smtplib
from email.mime.text import MIMEText

def envoyer_alerte_email(produit, ancien_prix, nouveau_prix):
    msg = MIMEText(f"Changement de prix pour {produit} :\nAncien prix : {ancien_prix}\nNouveau prix : {nouveau_prix}")
    msg['Subject'] = f"Alerte prix : {produit}"
    # // J'ai besoin de configuer un email avec accces : SnedOnBehalf
    msg['From'] = 
    msg['To'] = "bendrimou@gmail.com"

    with smtplib.SMTP('smtp.gmail.com', 587) as serveur:
        serveur.starttls()
        serveur.login("bendrimou@gmail.com", "itsASecret")
        serveur.send_message(msg)
```

---



## ğŸ§° AmÃ©liorations possibles


* ğŸ”¹ Tests unitaires avec `pytest`

---


---

## ğŸ‘¨â€ğŸ’» Exemple dâ€™exÃ©cution

```bash
uvicorn main:app --reload
```

âœ… Le scraping sâ€™exÃ©cute
âœ… Les donnÃ©es sont envoyÃ©es sur Google Sheets
âœ… Les endpoints FastAPI renvoient les rÃ©sultats au format JSON

---

